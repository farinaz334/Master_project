{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf15f57f-e5f5-4a38-beca-8714c12a2ce3",
   "metadata": {},
   "source": [
    "# Applying ML models on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501841d8-142f-4044-92fe-a77f967d67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import warnings\n",
    "\n",
    "def function_that_warns():\n",
    "    warnings.warn(\"This is a warning message\", UserWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    function_that_warns()  # This will not show a warning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38633a-b916-4a47-91d1-a706ce81cf1a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e930127f-421e-4f65-a2a8-cef9f0986f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_histograms(arr, variables, n_rows, n_cols):\n",
    "    df = pd.DataFrame(arr, columns =variables)\n",
    "    fig=plt.figure(figsize=(20, 20))\n",
    "    for i, var_name in enumerate(variables):\n",
    "        ax=fig.add_subplot(n_rows,n_cols,i+1)\n",
    "        df[var_name].hist(bins=10,ax=ax)\n",
    "        ax.set_title(var_name+\" Distribution\")\n",
    "    fig.tight_layout()  # Improves appearance a bit.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e11b7d-2c8c-4080-8854-1af7f0b4cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalsie the input base on the norm parametrs, if norm is none, no normalisation will happen\n",
    "def normalisation(X_train,X_test, norm ):\n",
    "    if norm != None:\n",
    "        scaler1 = norm\n",
    "        X_train  =  scaler1.fit_transform(X_train)\n",
    "        X_test  =  scaler1.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6ef0f4-ca19-4b0b-9d81-8fb7bd408a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_zscore(X,y, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(X))\n",
    "    mask = (z_scores < threshold).all(axis=1)\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(X.shape)\n",
    "    return  X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861c95a3-70de-4b90-a929-fac880f37a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate different performance metric for the model clf\n",
    "def clf_score(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    ma = mean_absolute_error(y_test,y_pred)\n",
    "    ms = mean_squared_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)   \n",
    "    return [ma,ms,r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08568310-4548-46b5-a881-e76af84935e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std for kfold results\n",
    "def show_statics(arr,type):  \n",
    "   \n",
    "    ma = np.mean([ x[0] for x in arr]), np.std([ x[0] for x in arr])\n",
    "    ms = np.mean([ x[1] for x in arr]), np.std([ x[1] for x in arr])\n",
    "    r2 = np.mean([ x[2] for x in arr]), np.std([ x[2] for x in arr])\n",
    "    \n",
    "    return [ma,ms,r2,type ] \n",
    "    \n",
    "# convert input array into a string \n",
    "def make_sring(a):\n",
    "    return  a[3]+' '+str(round(a[0][0],2))+' +-' + str(round(a[0][1],2))+ ' '+ str(round(a[1][0],0))+' +-' + str(round(a[1][1],0))+ ' '+str(round(a[2][0]*100,2))+' +-' + str(round(a[2][1]*100,2))+ ' '\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d556d462-f98d-4129-b38f-52a86cbee8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model and \n",
    "def train_clf(clf, X_tr,y_tr,X_test, y_test,   print_ind = False, to_string = True):\n",
    "    metrics_train = []\n",
    "    metrics_valid = []\n",
    "    metrics_test = []\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(X_tr)):\n",
    "             \n",
    "        X_train = X_tr[train_index]\n",
    "        y_train = y_tr[train_index]\n",
    "        X_valid = X_tr[valid_index]\n",
    "        y_valid = y_tr[valid_index]\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "\n",
    "        res = clf_score(clf,X_train,y_train)\n",
    "        if (print_ind): print('Train: ', res)\n",
    "        metrics_train.append(res)\n",
    "        \n",
    "        res = clf_score(clf,X_valid,y_valid)\n",
    "        if (print_ind): print('Valid: ', res)\n",
    "        metrics_valid.append(res)\n",
    "        \n",
    "        res = clf_score(clf,X_test,y_test)\n",
    "        if (print_ind): print('Test: ', res)\n",
    "        metrics_test.append(res)\n",
    "    #print(show_statics( Accs))\n",
    "    if to_string :\n",
    "        return make_sring(show_statics( metrics_train,'train')), make_sring(show_statics( metrics_valid,'valid'))  , make_sring(show_statics( metrics_test,'test'))  \n",
    "    else:\n",
    "        return (show_statics( metrics_train,'train')), (show_statics( metrics_valid,'valid'))  , (show_statics( metrics_test,'test'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "021b4dd6-39d9-4556-896b-a4ee76fd52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model,X_train,y_train,X_test, y_test, to_string = True ):\n",
    "       \n",
    "    ma_t,ms_t,r2_t = train_clf(model,X_train,y_train.reshape(-1, 1),X_test, y_test,False, to_string )\n",
    "     \n",
    "    return ma_t,ms_t,r2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43ff18d-70e5-471e-9aa2-2482490471f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, target , remove_outliers = True, log = True  ):\n",
    "    df = pd.read_csv(path)\n",
    "    df.head()\n",
    "    df['Region'] = pd.factorize( df['Region'] )[0]\n",
    "    df['Industry'] = pd.factorize( df['Industry'] )[0]\n",
    "    df['Employee _size'] = pd.factorize( df['Employee _size'] )[0]\n",
    "\n",
    "    \n",
    "    y = df[target].to_numpy()\n",
    "    X = df.drop(target, axis=1).to_numpy()\n",
    "\n",
    "    \n",
    "    if remove_outliers:\n",
    "        X , y = remove_outliers_zscore (X,y)\n",
    "    if log:\n",
    "      for i in range(5,X.shape[1],1):\n",
    "        min_value = np.min(X[:,i],0) \n",
    "        if (min_value< 0):\n",
    "            X[:,i] = X[:,i] + abs(min_value) + 0.0000001\n",
    "        \n",
    "        X[:,i] = np.log1p(X[:,i])\n",
    "    \n",
    "    \n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=10,  \n",
    "                                   test_size=0.2,  \n",
    "                                   shuffle=True)\n",
    "    X_train,X_test = normalisation(X_train,X_test, StandardScaler())\n",
    "     \n",
    "       \n",
    "    return X_train, X_test,y_train, y_test, X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22453fa7-bab5-411b-8204-1e52756b11b0",
   "metadata": {},
   "source": [
    "## Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f8bec-7591-465f-8ea9-2ce9a59ed365",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6fae80-a080-4d58-8d1b-4cf4e34d80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading files \n",
    "imputed_file_knn = \"Cleaned_data_knn_imputed_df.csv\"\n",
    "imputed_file_em = \"Cleaned_data_em_imputed_df.csv\"\n",
    "imputed_file_ct = \"Cleaned_data_imputed_df.csv\" \n",
    "     \n",
    "df_features =  pd.read_csv(imputed_file_knn).columns\n",
    "df_target = \"Turnover\"\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle = True)\n",
    "norm =  StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a58c45-988d-4944-ab2b-90bba62a7225",
   "metadata": {},
   "source": [
    "### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8d7b241-dd35-4be6-b868-3f344ec2deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn ,X_test_knn , y_train_knn ,y_test_knn,X_knn,y_knn  = read_csv(imputed_file_knn,df_target, remove_outliers = False, log= False)\n",
    "X_train_em ,X_test_em , y_train_em ,y_test_em,X_em,y_em = read_csv(imputed_file_em,df_target, remove_outliers = False, log= False)\n",
    "X_train_ct ,X_test_ct , y_train_ct ,y_test_ct,X_ct,y_ct= read_csv(imputed_file_ct,df_target, remove_outliers = False, log= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e03b6f-41ee-4caf-af8a-079d4f2f9021",
   "metadata": {},
   "source": [
    "# Aplying Machine learning model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c67c30-b466-4094-b876-4aefd655efaa",
   "metadata": {},
   "source": [
    "## Domain Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eb0d25e-43c2-4cee-80dd-f6fc9f6ef0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_features = pd.read_csv(imputed_file_knn).columns.to_list()\n",
    "df_features.remove(\"Turnover\")\n",
    "df_features.append(\"Turnover\")\n",
    "\n",
    "df_knn = pd.DataFrame(data= np.concatenate((X_knn,y_knn.reshape(-1,1)), axis = 1),columns= df_features)\n",
    "df_em = pd.DataFrame(data= np.concatenate((X_em,y_em.reshape(-1,1)), axis = 1),columns= df_features)\n",
    "df_ct = pd.DataFrame(data= np.concatenate((X_ct,y_ct.reshape(-1,1)), axis = 1),columns= df_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa9988ae-8c12-4715-9a78-7bb53d398a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_knowledge(numerical_df , threshold = 0.8):\n",
    "\n",
    "\n",
    "    correlation_matrix = numerical_df.corr()\n",
    "    \n",
    "    # Find pairs of features with correlation greater than the threshold\n",
    "    high_correlation_pairs = np.where(correlation_matrix > threshold)\n",
    "    high_correlation_pairs = [(correlation_matrix.index[x], correlation_matrix.columns[y]) \n",
    "                          for x, y in zip(*high_correlation_pairs) if x != y and x < y]\n",
    "    \n",
    "    features_to_drop = []\n",
    "    # Display the high correlation pairs\n",
    "    for pair in high_correlation_pairs:\n",
    "        feature1, feature2 = pair\n",
    "        correlation_value = correlation_matrix.loc[feature1, feature2]\n",
    "        #print(f\"Correlation between {feature1} and {feature2}: {correlation_value:.2f}\")\n",
    "        features_to_drop.append(feature1)\n",
    "        \n",
    "        \n",
    "    return list(set(features_to_drop))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa8e3f3e-957b-47ef-9567-d53ae3d319d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df,X_train,X_test, threshold = 0.8):\n",
    "    df_dk = domain_knowledge(df , threshold = 0.8)\n",
    "    features_indexs = []\n",
    "    for f in df_dk:\n",
    "        ind = df_features.index(f)\n",
    "        #print(f, ind)\n",
    "        features_indexs.append(ind)\n",
    "    new_X_train = pd.DataFrame(X_train)\n",
    "    new_X_train.drop(new_X_train.columns[features_indexs], axis=1, inplace=True)\n",
    "\n",
    "    new_X_test = pd.DataFrame(X_test)\n",
    "    new_X_test.drop(new_X_test.columns[features_indexs], axis=1, inplace=True)\n",
    "    \n",
    "    return new_X_train.to_numpy() , new_X_test.to_numpy()  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_X_train_knn , new_X_test_knn = remove_columns(df_knn,X_train_knn,X_test_knn, threshold = 0.8)\n",
    "new_X_train_em , new_X_test_em   = remove_columns(df_em,X_train_em,X_test_em, threshold = 0.8)\n",
    "new_X_train_ct , new_X_test_ct   = remove_columns(df_ct,X_train_ct,X_test_ct, threshold = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8fbdf79-8c4f-4cb3-9b00-eb0009e3635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "KNN :  ('train 6226.67 +-135.08 388360546.0 +-19438550.0 7.44 +-0.27 ', 'valid 6235.17 +-552.87 389860988.0 +-175293359.0 8.0 +-3.22 ', 'test 6117.95 +-67.63 361698524.0 +-127812.0 6.9 +-0.03 ')\n",
      "EM  :  ('train 6224.65 +-133.71 389488893.0 +-19417232.0 7.17 +-0.26 ', 'valid 6232.88 +-571.24 391093178.0 +-175137966.0 7.65 +-3.34 ', 'test 6139.93 +-60.92 362552967.0 +-230331.0 6.68 +-0.06 ')\n",
      "CT  :  ('train 6224.65 +-133.71 389488893.0 +-19417232.0 7.17 +-0.26 ', 'valid 6232.88 +-571.24 391093178.0 +-175137966.0 7.65 +-3.34 ', 'test 6139.93 +-60.92 362552967.0 +-230331.0 6.68 +-0.06 ')\n",
      "GradientBoostingRegressor()\n",
      "KNN :  ('train 2301.06 +-60.68 43082502.0 +-1970272.0 89.71 +-0.67 ', 'valid 2440.53 +-216.21 53987104.0 +-17434614.0 84.88 +-6.73 ', 'test 2277.99 +-50.53 38273017.0 +-1484430.0 90.15 +-0.38 ')\n",
      "EM  :  ('train 2259.9 +-26.47 40070888.0 +-1215588.0 90.43 +-0.51 ', 'valid 2409.84 +-233.59 53075624.0 +-19919291.0 85.56 +-6.08 ', 'test 2261.17 +-28.46 37006367.0 +-2347573.0 90.47 +-0.6 ')\n",
      "CT  :  ('train 2259.9 +-26.47 40070888.0 +-1215588.0 90.43 +-0.51 ', 'valid 2409.85 +-233.97 53059209.0 +-19939135.0 85.56 +-6.08 ', 'test 2261.45 +-28.38 37019933.0 +-2334388.0 90.47 +-0.6 ')\n",
      "RandomForestRegressor()\n",
      "KNN :  ('train 343.48 +-9.44 2992137.0 +-197868.0 99.28 +-0.06 ', 'valid 903.52 +-140.63 20310417.0 +-8792614.0 94.02 +-3.94 ', 'test 892.31 +-33.11 17202018.0 +-1776023.0 95.57 +-0.46 ')\n",
      "EM  :  ('train 383.93 +-6.61 3575777.0 +-162343.0 99.15 +-0.05 ', 'valid 1024.04 +-148.42 24568469.0 +-9288966.0 92.77 +-4.25 ', 'test 1009.2 +-23.28 19889401.0 +-1508000.0 94.88 +-0.39 ')\n",
      "CT  :  ('train 381.67 +-5.92 3507305.0 +-176361.0 99.16 +-0.07 ', 'valid 1021.12 +-158.94 24811527.0 +-9647775.0 92.65 +-4.39 ', 'test 1007.42 +-27.33 20020207.0 +-1563052.0 94.85 +-0.4 ')\n",
      "SVR()\n",
      "KNN :  ('train 4538.5 +-80.1 435790318.0 +-20610829.0 -3.87 +-0.1 ', 'valid 4539.44 +-721.52 435821113.0 +-185511330.0 -4.39 +-1.34 ', 'test 4483.62 +-0.19 404384779.0 +-32999.0 -4.09 +-0.01 ')\n",
      "EM  :  ('train 4538.24 +-80.13 435763088.0 +-20611078.0 -3.87 +-0.1 ', 'valid 4539.17 +-721.74 435794146.0 +-185505646.0 -4.38 +-1.34 ', 'test 4483.42 +-0.16 404366289.0 +-31462.0 -4.09 +-0.01 ')\n",
      "CT  :  ('train 4538.24 +-80.13 435763089.0 +-20611078.0 -3.87 +-0.1 ', 'valid 4539.17 +-721.74 435794146.0 +-185505645.0 -4.38 +-1.34 ', 'test 4483.42 +-0.16 404366289.0 +-31462.0 -4.09 +-0.01 ')\n",
      "MLPRegressor(alpha=1e-05, hidden_layer_sizes=(32, 32), max_iter=5000,\n",
      "             random_state=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN :  ('train 3333.8 +-155.22 92202532.0 +-15237141.0 77.86 +-4.47 ', 'valid 3734.13 +-395.49 132704947.0 +-56657500.0 65.49 +-13.24 ', 'test 3592.04 +-149.41 107636958.0 +-20019205.0 72.29 +-5.15 ')\n",
      "EM  :  ('train 3562.91 +-785.63 132486361.0 +-84931769.0 68.27 +-20.51 ', 'valid 3863.7 +-707.46 167999814.0 +-97888145.0 57.0 +-21.06 ', 'test 3875.64 +-653.66 163052802.0 +-66739396.0 58.03 +-17.18 ')\n",
      "CT  :  ('train 3562.44 +-785.23 133018570.0 +-84689135.0 68.13 +-20.46 ', 'valid 3848.04 +-713.7 164907343.0 +-98590969.0 57.65 +-21.59 ', 'test 3877.46 +-653.0 163873177.0 +-66482200.0 57.82 +-17.11 ')\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "          LinearRegression(),\n",
    "          GradientBoostingRegressor(),\n",
    "          RandomForestRegressor(), \n",
    "          SVR(), \n",
    "          MLPRegressor( alpha=1e-5, max_iter=5000,hidden_layer_sizes=(32, 32), random_state=1),\n",
    "         ] \n",
    "for model in models:\n",
    "        print(model)\n",
    "        print('KNN : ', apply_model(model, new_X_train_knn, y_train_knn ,new_X_test_knn  ,y_test_knn))\n",
    "        print('EM  : ', apply_model(model, new_X_train_em, y_train_em ,new_X_test_em  ,y_test_em))\n",
    "        print('CT  : ',apply_model(model, new_X_train_ct, y_train_ct ,new_X_test_ct  ,y_test_ct))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb96e8-5ddb-4087-834a-03497dd6adb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
