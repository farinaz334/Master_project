{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf15f57f-e5f5-4a38-beca-8714c12a2ce3",
   "metadata": {},
   "source": [
    "# Applying ML models on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501841d8-142f-4044-92fe-a77f967d67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries.\n",
    "import warnings\n",
    "\n",
    "def function_that_warns():\n",
    "    warnings.warn(\"This is a warning message\", UserWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    function_that_warns()  # This will not show a warning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38633a-b916-4a47-91d1-a706ce81cf1a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e930127f-421e-4f65-a2a8-cef9f0986f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_histograms(arr, variables, n_rows, n_cols):\n",
    "    df = pd.DataFrame(arr, columns =variables)\n",
    "    fig=plt.figure(figsize=(20, 20))\n",
    "    for i, var_name in enumerate(variables):\n",
    "        ax=fig.add_subplot(n_rows,n_cols,i+1)\n",
    "        df[var_name].hist(bins=10,ax=ax)\n",
    "        ax.set_title(var_name+\" Distribution\")\n",
    "    fig.tight_layout()  # Improves appearance a bit.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e11b7d-2c8c-4080-8854-1af7f0b4cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalsie the input base on the norm parametrs, if norm is none, no normalisation will happen\n",
    "def normalisation(X_train,X_test, norm ):\n",
    "    if norm != None:\n",
    "        scaler1 = norm\n",
    "        X_train  =  scaler1.fit_transform(X_train)\n",
    "        X_test  =  scaler1.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a6ef0f4-ca19-4b0b-9d81-8fb7bd408a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_zscore(X,y, threshold=3):\n",
    "    z_scores = np.abs(stats.zscore(X))\n",
    "    mask = (z_scores < threshold).all(axis=1)\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(X.shape)\n",
    "    return  X,y\n",
    "def read_csv(path, target , remove_outliers = True, log = True  ):\n",
    "    df = pd.read_csv(path)\n",
    "    df['Region'] = pd.factorize( df['Region'] )[0]\n",
    "    df['Industry'] = pd.factorize( df['Industry'] )[0]\n",
    "    df['Employee _size'] = pd.factorize( df['Employee _size'] )[0]\n",
    "\n",
    "    \n",
    "    y = df[target].to_numpy()\n",
    "    X = df.drop(target, axis=1).to_numpy()\n",
    "    if remove_outliers:\n",
    "        X , y = remove_outliers_zscore (X,y)\n",
    "    if log:\n",
    "      \n",
    "        X[:,5:] = np.log1p(X[:,5:])\n",
    "    \n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=10,  \n",
    "                                   test_size=0.2,  \n",
    "                                   shuffle=True)\n",
    "    X_train,X_test = normalisation(X_train,X_test, StandardScaler())\n",
    "       \n",
    "    return X_train, X_test,y_train, y_test, X,y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861c95a3-70de-4b90-a929-fac880f37a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate different performance metric for the model clf\n",
    "def clf_score(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    ma = mean_absolute_error(y_test,y_pred)\n",
    "    ms = mean_squared_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)   \n",
    "    return [ma,ms,r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08568310-4548-46b5-a881-e76af84935e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean and std for kfold results\n",
    "def show_statics(arr,type):  \n",
    "   \n",
    "    ma = np.mean([ x[0] for x in arr]), np.std([ x[0] for x in arr])\n",
    "    ms = np.mean([ x[1] for x in arr]), np.std([ x[1] for x in arr])\n",
    "    r2 = np.mean([ x[2] for x in arr]), np.std([ x[2] for x in arr])\n",
    "    \n",
    "    return [ma,ms,r2,type ] \n",
    "    \n",
    "# convert input array into a string \n",
    "def make_sring(a):\n",
    "    return  a[3]+' '+str(round(a[0][0],2))+' +-' + str(round(a[0][1],2))+ ' '+ str(round(a[1][0],0))+' +-' + str(round(a[1][1],0))+ ' '+str(round(a[2][0]*100,2))+' +-' + str(round(a[2][1]*100,2))+ ' '\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d556d462-f98d-4129-b38f-52a86cbee8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model and \n",
    "def train_clf(clf, X_tr,y_tr,X_test, y_test,   print_ind = False, to_string = True):\n",
    "    metrics_train = []\n",
    "    metrics_valid = []\n",
    "    metrics_test = []\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(X_tr)):\n",
    "             \n",
    "        X_train = X_tr[train_index]\n",
    "        y_train = y_tr[train_index]\n",
    "        X_valid = X_tr[valid_index]\n",
    "        y_valid = y_tr[valid_index]\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "\n",
    "        res = clf_score(clf,X_train,y_train)\n",
    "        if (print_ind): print('Train: ', res)\n",
    "        metrics_train.append(res)\n",
    "        \n",
    "        res = clf_score(clf,X_valid,y_valid)\n",
    "        if (print_ind): print('Valid: ', res)\n",
    "        metrics_valid.append(res)\n",
    "        \n",
    "        res = clf_score(clf,X_test,y_test)\n",
    "        if (print_ind): print('Test: ', res)\n",
    "        metrics_test.append(res)\n",
    "    #print(show_statics( Accs))\n",
    "    if to_string :\n",
    "        return make_sring(show_statics( metrics_train,'train')), make_sring(show_statics( metrics_valid,'valid'))  , make_sring(show_statics( metrics_test,'test'))  \n",
    "    else:\n",
    "        return (show_statics( metrics_train,'train')), (show_statics( metrics_valid,'valid'))  , (show_statics( metrics_test,'test'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "021b4dd6-39d9-4556-896b-a4ee76fd52ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model,X_train,y_train,X_test, y_test, to_string = True ):\n",
    "       \n",
    "    ma_t,ms_t,r2_t = train_clf(model,X_train,y_train.reshape(-1, 1),X_test, y_test,False, to_string )\n",
    "     \n",
    "    return ma_t,ms_t,r2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43ff18d-70e5-471e-9aa2-2482490471f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, target , remove_outliers = True, log = True  ):\n",
    "    df = pd.read_csv(path)\n",
    "    df.head()\n",
    "    df['Region'] = pd.factorize( df['Region'] )[0]\n",
    "    df['Industry'] = pd.factorize( df['Industry'] )[0]\n",
    "    df['Employee _size'] = pd.factorize( df['Employee _size'] )[0]\n",
    "\n",
    "    \n",
    "    y = df[target].to_numpy()\n",
    "    X = df.drop(target, axis=1).to_numpy()\n",
    "    if remove_outliers:\n",
    "        X , y = remove_outliers_zscore (X,y)\n",
    "    if log:\n",
    "      for i in range(5,X.shape[1],1):\n",
    "        min_value = np.min(X[:,i],0) \n",
    "        if (min_value< 0):\n",
    "            X[:,i] = X[:,i] + abs(min_value) + 0.0000001\n",
    "        \n",
    "        X[:,i] = np.log1p(X[:,i])\n",
    "    \n",
    "    \n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=10,  \n",
    "                                   test_size=0.2,  \n",
    "                                   shuffle=True)\n",
    "    #X_train,X_test = normalisation(X_train,X_test, StandardScaler())\n",
    "       \n",
    "    return X_train, X_test,y_train, y_test, X,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22453fa7-bab5-411b-8204-1e52756b11b0",
   "metadata": {},
   "source": [
    "## Prepration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f8bec-7591-465f-8ea9-2ce9a59ed365",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6fae80-a080-4d58-8d1b-4cf4e34d80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading files \n",
    "imputed_file_knn = \"Cleaned_data_knn_imputed_df.csv\"\n",
    "imputed_file_em = \"Cleaned_data_em_imputed_df.csv\"\n",
    "imputed_file_ct = \"Cleaned_data_imputed_df.csv\" \n",
    "     \n",
    "df_features =  pd.read_csv(imputed_file_knn).columns\n",
    "df_target = \"Turnover\"\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle = True)\n",
    "norm =  StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a58c45-988d-4944-ab2b-90bba62a7225",
   "metadata": {},
   "source": [
    "### Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8d7b241-dd35-4be6-b868-3f344ec2deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn ,X_test_knn , y_train_knn ,y_test_knn,X_knn,y_knn  = read_csv(imputed_file_knn,df_target, remove_outliers = False, log= False)\n",
    "X_train_em ,X_test_em , y_train_em ,y_test_em,X_em,y_em = read_csv(imputed_file_em,df_target, remove_outliers = False, log= False)\n",
    "X_train_ct ,X_test_ct , y_train_ct ,y_test_ct,X_ct,y_ct= read_csv(imputed_file_ct,df_target, remove_outliers = False, log= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e03b6f-41ee-4caf-af8a-079d4f2f9021",
   "metadata": {},
   "source": [
    "# Aplying Machine learning model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b28dda-4fd9-4727-bcf7-4a682080352e",
   "metadata": {},
   "source": [
    "## Not applying any freture reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8eeaed-c7fc-483b-8659-9afa62b356a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "          LinearRegression(),\n",
    "          GradientBoostingRegressor(),\n",
    "          RandomForestRegressor(), \n",
    "          SVR(), \n",
    "          MLPRegressor( alpha=1e-5, max_iter=5000,hidden_layer_sizes=(32, 32), random_state=1),\n",
    "         ]\n",
    "\n",
    "models_name = [\n",
    "         'Linear Regression',\n",
    "          'Gradient Boosting Regressor',\n",
    "          'Random Forest Regressor', \n",
    "           'SVR', \n",
    "           'MLP Regressor'  \n",
    "]\n",
    "\n",
    "for model in models:\n",
    "        print(model)\n",
    "        print('KNN : ', apply_model(model, X_train_knn, y_train_knn ,X_test_knn  ,y_test_knn))\n",
    "        print('EM  : ', apply_model(model, X_train_em, y_train_em ,X_test_em  ,y_test_em))\n",
    "        print('CT  : ',apply_model(model, X_train_ct, y_train_ct ,X_test_ct  ,y_test_ct))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38064120-e621-4fc3-acf5-e5b15039111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_knn, y_train_knn )\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train_knn, feature_names=df_features, mode='regression')\n",
    "i = 0  # Index of the instance to explain\n",
    "exp = explainer.explain_instance(X_test_knn[i], model.predict, num_features=5)\n",
    "exp.show_in_notebook(show_table=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0f54f-33b4-4862-8741-b77d12c499ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer\n",
    "explainer = shap.Explainer(model, X_train_knn)\n",
    "# Explain a single instance\n",
    "i = 0  # Index of the instance to explain\n",
    "explainer = shap.Explainer(model.predict,X_test_knn)\n",
    "\n",
    "# Visualize the explanation\n",
    "shap_values = explainer(X_test_knn)\n",
    "shap.plots.bar(shap_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c67c30-b466-4094-b876-4aefd655efaa",
   "metadata": {},
   "source": [
    "## Domain Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a48999-2a6f-4d71-8cec-f4e997d52b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0d25e-43c2-4cee-80dd-f6fc9f6ef0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_features = pd.read_csv(imputed_file_knn).columns.to_list()\n",
    "df_features.remove(\"Turnover\")\n",
    "df_features.append(\"Turnover\")\n",
    "\n",
    "df_knn = pd.DataFrame(data= np.concatenate((X_knn,y_knn.reshape(-1,1)), axis = 1),columns= df_features)\n",
    "df_em = pd.DataFrame(data= np.concatenate((X_em,y_em.reshape(-1,1)), axis = 1),columns= df_features)\n",
    "df_ct = pd.DataFrame(data= np.concatenate((X_ct,y_ct.reshape(-1,1)), axis = 1),columns= df_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9988ae-8c12-4715-9a78-7bb53d398a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_knowledge(numerical_df , threshold = 0.8):\n",
    "\n",
    "\n",
    "    correlation_matrix = numerical_df.corr()\n",
    "    \n",
    "    # Find pairs of features with correlation greater than the threshold\n",
    "    high_correlation_pairs = np.where(correlation_matrix > threshold)\n",
    "    high_correlation_pairs = [(correlation_matrix.index[x], correlation_matrix.columns[y]) \n",
    "                          for x, y in zip(*high_correlation_pairs) if x != y and x < y]\n",
    "    \n",
    "    features_to_drop = []\n",
    "    # Display the high correlation pairs\n",
    "    for pair in high_correlation_pairs:\n",
    "        feature1, feature2 = pair\n",
    "        correlation_value = correlation_matrix.loc[feature1, feature2]\n",
    "        #print(f\"Correlation between {feature1} and {feature2}: {correlation_value:.2f}\")\n",
    "        features_to_drop.append(feature1)\n",
    "        \n",
    "        \n",
    "    return list(set(features_to_drop))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e3f3e-957b-47ef-9567-d53ae3d319d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(df,X_train,X_test, threshold = 0.8):\n",
    "    df_dk = domain_knowledge(df , threshold = 0.8)\n",
    "    features_indexs = []\n",
    "    for f in df_dk:\n",
    "        ind = df_features.index(f)\n",
    "        #print(f, ind)\n",
    "        features_indexs.append(ind)\n",
    "    new_X_train = pd.DataFrame(X_train)\n",
    "    new_X_train.drop(new_X_train.columns[features_indexs], axis=1, inplace=True)\n",
    "\n",
    "    new_X_test = pd.DataFrame(X_test)\n",
    "    new_X_test.drop(new_X_test.columns[features_indexs], axis=1, inplace=True)\n",
    "    \n",
    "    return new_X_train.to_numpy() , new_X_test.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_X_train_knn , new_X_test_knn = remove_columns(df_knn,X_train_knn,X_test_knn, threshold = 0.8)\n",
    "new_X_train_em , new_X_test_em   = remove_columns(df_em,X_train_em,X_test_em, threshold = 0.8)\n",
    "new_X_train_ct , new_X_test_ct   = remove_columns(df_ct,X_train_ct,X_test_ct, threshold = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fbdf79-8c4f-4cb3-9b00-eb0009e3635f",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "for model in models:\n",
    "        print(model)\n",
    "        print('KNN : ', apply_model(model, new_X_train_knn, y_train_knn ,new_X_test_knn  ,y_test_knn))\n",
    "        print('EM  : ', apply_model(model, new_X_train_em, y_train_em ,new_X_test_em  ,y_test_em))\n",
    "        print('CT  : ',apply_model(model, new_X_train_ct, y_train_ct ,new_X_test_ct  ,y_test_ct))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b1d9f5-8e2a-48b8-b884-f3925e2d228e",
   "metadata": {},
   "source": [
    "## Multicollinearity Assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01662e65-8fe7-471e-83d6-4f6cbf1d1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa3ab45-4f5d-43f7-bd0b-ab2a86da2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vif(df,considered_features):\n",
    "    \n",
    "    X = df[considered_features]\n",
    "    # the calculation of variance inflation requires a constant\n",
    "    X['intercept'] = 1\n",
    "    \n",
    "    # create dataframe to store vif values\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"Variable\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    vif = vif[vif['Variable']!='intercept']\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be951db3-c74c-41d7-9437-66a2a51b7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Multi_assessment(X_df, y_df, model, imputing_title, model_title):\n",
    "    fn = df_features\n",
    "    fn.remove('Turnover')\n",
    "    \n",
    "    df = pd.DataFrame(X_df,columns=fn)\n",
    "    X = df.to_numpy()\n",
    "    y = y_df\n",
    "    \n",
    "    acc_train_0 = []\n",
    "    acc_test_0 = []\n",
    "    acc_valid_0 = []\n",
    "    \n",
    "    acc_train_1 = []\n",
    "    acc_test_1 = []\n",
    "    acc_valid_1 = []\n",
    "    \n",
    "    acc_train_2 = []\n",
    "    acc_test_2 = []\n",
    "    acc_valid_2 = []\n",
    "    \n",
    "    data_list = []\n",
    "    for i in range(42):\n",
    "       \n",
    "        considered_features = df.columns.to_list()\n",
    "        a = compute_vif(df,considered_features).sort_values('VIF', ascending=False)\n",
    "        var_list = a['Variable'].to_list()\n",
    "        vif_list = a['VIF'].to_list()\n",
    "        \n",
    "        var = var_list[0]\n",
    "        #print(var)\n",
    "        data_list.append(var)\n",
    "        df = df.drop(var, axis=1)\n",
    "        \n",
    "        \n",
    "        #'''    \n",
    "        X = df.to_numpy()\n",
    "        y = y_knn\n",
    "         \n",
    "        \n",
    "        X_train, X_test,y_train, y_test = train_test_split(X,y , \n",
    "                                       random_state=10,  \n",
    "                                       test_size=0.2,  \n",
    "                                       shuffle=True)\n",
    "    \n",
    " \n",
    "        b = apply_model(model, X_train,y_train.reshape(-1, 1), X_test, y_test.reshape(-1, 1), to_string = True)\n",
    "        #print('KNN : ',df.shape, b)\n",
    "        acc_train_0.append( b[0][0][0])\n",
    "        acc_valid_0.append( b[1][0][0])\n",
    "        acc_test_0.append( b[2][0][0])\n",
    "        acc_train_1.append( b[0][1][0])\n",
    "        acc_valid_1.append( b[1][1][0])\n",
    "        acc_test_1.append( b[2][1][0])\n",
    "        acc_train_2.append( b[0][2][0])\n",
    "        acc_valid_2.append( b[1][2][0])\n",
    "        acc_test_2.append( b[2][2][0])\n",
    "        #'''\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_0, label=\"Train MAE\")\n",
    "    plt.plot(data_list, acc_valid_0, label=\"Valid MAE\")\n",
    "    plt.plot(data_list, acc_test_0, label=\"Test MAE\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_1, label=\"Train MSE\")\n",
    "    plt.plot(data_list, acc_valid_1, label=\"Valid MSE\")\n",
    "    plt.plot(data_list, acc_test_1, label=\"Test MSE\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_2, label=\"Train R2\")\n",
    "    plt.plot(data_list, acc_valid_2, label=\"Valid R2\")\n",
    "    plt.plot(data_list, acc_test_2, label=\"Test R2\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    np.savetxt(model_title+'_acc_train_0.txt',acc_train_0)\n",
    "    np.savetxt(model_title+'_acc_train_1.txt',acc_train_1)\n",
    "    np.savetxt(model_title+'_acc_train_2.txt',acc_train_2)\n",
    "    np.savetxt(model_title+'_acc_valid_0.txt',acc_valid_0)\n",
    "    np.savetxt(model_title+'_acc_valid_1.txt',acc_valid_1)\n",
    "    np.savetxt(model_title+'_acc_valid_2.txt',acc_valid_2)\n",
    "    np.savetxt(model_title+'_acc_test_0.txt',acc_test_0)\n",
    "    np.savetxt(model_title+'_acc_test_1.txt',acc_test_1)\n",
    "    np.savetxt(model_title+'_acc_test_2.txt',acc_test_2)\n",
    "    return  acc_train_0 ,acc_test_0,acc_valid_0,acc_train_1,acc_test_1,acc_valid_1,acc_train_2,acc_test_2,acc_valid_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef94291-5ad9-4fb2-bb2c-ee3853203525",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "for model, model_title in zip( models,models_name):\n",
    "        print(model)\n",
    "        Multi_assessment(X_knn,y_knn, model, 'KNN', model_title)\n",
    "        Multi_assessment(X_em,y_em, model, 'EM', model_title)\n",
    "        Multi_assessment(X_ct,y_ct, model, 'CT', model_title)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7375e9a-4090-40b4-a394-7e076f95ca5d",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae7bfc74-258b-4703-b740-0e9f6e545e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for n_components in range(2,43,1):\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    pca_X_train_knn = pca.fit_transform(X_train_knn)\n",
    "    pca_X_test_knn = pca.transform(X_test_knn)\n",
    "    eigenvalues_knn = pca.explained_variance_\n",
    "    \n",
    "    pca_X_train_em = pca.fit_transform(X_train_em)\n",
    "    pca_X_test_em = pca.transform(X_test_em)\n",
    "    eigenvalues_em = pca.explained_variance_\n",
    "    \n",
    "    \n",
    "    model = LinearRegression(positive=False)\n",
    "    #print(n_components , model)\n",
    "    knn_LR =  apply_model(model, pca_X_train_knn, y_train_knn  ,pca_X_test_knn  ,y_test_knn , to_string = False)\n",
    "    EM_LR = apply_model(model, pca_X_train_em, y_train_em ,pca_X_test_em  ,y_test_em, to_string = False )\n",
    "    CT_LR = apply_model(model, X_train_ct, y_train_ct ,X_test_ct  ,y_test_ct, to_string = False )\n",
    "    #print('-----')\n",
    "    acc.append([knn_LR,EM_LR])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab5577bd-0c50-43f5-b9b8-9fb72de140aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PCA_assessment(X_train,y_train, X_test, y_test,  model, imputing_title, model_title):\n",
    "   \n",
    " \n",
    "    \n",
    "    acc_train_0 = []\n",
    "    acc_test_0 = []\n",
    "    acc_valid_0 = []\n",
    "    \n",
    "    acc_train_1 = []\n",
    "    acc_test_1 = []\n",
    "    acc_valid_1 = []\n",
    "    \n",
    "    acc_train_2 = []\n",
    "    acc_test_2 = []\n",
    "    acc_valid_2 = []\n",
    "    \n",
    "    data_list = []\n",
    "    for i in range(42):\n",
    "\n",
    "\n",
    "        pca = PCA(n_components=n_components)\n",
    "       \n",
    "        pca_X_train = pca.fit_transform(X_train)\n",
    "        pca_X_test = pca.transform(X_test)\n",
    "        eigenvalues_ = pca.explained_variance_\n",
    "\n",
    "        \n",
    "    \n",
    " \n",
    " \n",
    "        b = apply_model(model, X_train,y_train.reshape(-1, 1), X_test, y_test.reshape(-1, 1), to_string = True)\n",
    "        print('KNN : ',i, b)\n",
    "        acc_train_0.append( b[0][0][0])\n",
    "        acc_valid_0.append( b[1][0][0])\n",
    "        acc_test_0.append( b[2][0][0])\n",
    "        acc_train_1.append( b[0][1][0])\n",
    "        acc_valid_1.append( b[1][1][0])\n",
    "        acc_test_1.append( b[2][1][0])\n",
    "        acc_train_2.append( b[0][2][0])\n",
    "        acc_valid_2.append( b[1][2][0])\n",
    "        acc_test_2.append( b[2][2][0])\n",
    "        #'''\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_0, label=\"Train MAE\")\n",
    "    plt.plot(data_list, acc_valid_0, label=\"Valid MAE\")\n",
    "    plt.plot(data_list, acc_test_0, label=\"Test MAE\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_1, label=\"Train MSE\")\n",
    "    plt.plot(data_list, acc_valid_1, label=\"Valid MSE\")\n",
    "    plt.plot(data_list, acc_test_1, label=\"Test MSE\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_2, label=\"Train R2\")\n",
    "    plt.plot(data_list, acc_valid_2, label=\"Valid R2\")\n",
    "    plt.plot(data_list, acc_test_2, label=\"Test R2\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    np.savetxt(model_title+'_acc_train_0.txt',acc_train_0)\n",
    "    np.savetxt(model_title+'_acc_train_1.txt',acc_train_1)\n",
    "    np.savetxt(model_title+'_acc_train_2.txt',acc_train_2)\n",
    "    np.savetxt(model_title+'_acc_valid_0.txt',acc_valid_0)\n",
    "    np.savetxt(model_title+'_acc_valid_1.txt',acc_valid_1)\n",
    "    np.savetxt(model_title+'_acc_valid_2.txt',acc_valid_2)\n",
    "    np.savetxt(model_title+'_acc_test_0.txt',acc_test_0)\n",
    "    np.savetxt(model_title+'_acc_test_1.txt',acc_test_1)\n",
    "    np.savetxt(model_title+'_acc_test_2.txt',acc_test_2)\n",
    "    '''\n",
    "    return  acc_train_0 ,acc_test_0,acc_valid_0,acc_train_1,acc_test_1,acc_valid_1,acc_train_2,acc_test_2,acc_valid_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03a9cb8e-d181-4458-affa-13df55985975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def PCA_assessment(X_train,y_train, X_test, y_test,  model, imputing_title, model_title):\n",
    "   \n",
    " \n",
    "    \n",
    "    acc_train_0 = []\n",
    "    acc_test_0 = []\n",
    "    acc_valid_0 = []\n",
    "    \n",
    "    acc_train_1 = []\n",
    "    acc_test_1 = []\n",
    "    acc_valid_1 = []\n",
    "    \n",
    "    acc_train_2 = []\n",
    "    acc_test_2 = []\n",
    "    acc_valid_2 = []\n",
    "    \n",
    "    data_list = []\n",
    "    for i in range(41):\n",
    "\n",
    "\n",
    "        pca = PCA(n_components=n_components)\n",
    "       \n",
    "        pca_X_train = pca.fit_transform(X_train)\n",
    "        pca_X_test = pca.transform(X_test)\n",
    "        eigenvalues_ = pca.explained_variance_\n",
    "\n",
    "        \n",
    "    \n",
    " \n",
    " \n",
    "        b = apply_model(model, X_train,y_train.reshape(-1, 1), X_test, y_test.reshape(-1, 1), to_string = True)\n",
    "        print(model_title , '-', imputing_title ,i, b)\n",
    "        acc_train_0.append( b[0][0][0])\n",
    "        acc_valid_0.append( b[1][0][0])\n",
    "        acc_test_0.append( b[2][0][0])\n",
    "        acc_train_1.append( b[0][1][0])\n",
    "        acc_valid_1.append( b[1][1][0])\n",
    "        acc_test_1.append( b[2][1][0])\n",
    "        acc_train_2.append( b[0][2][0])\n",
    "        acc_valid_2.append( b[1][2][0])\n",
    "        acc_test_2.append( b[2][2][0])\n",
    "        #'''\n",
    "    \n",
    "    '''\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_0, label=\"Train MAE\")\n",
    "    plt.plot(data_list, acc_valid_0, label=\"Valid MAE\")\n",
    "    plt.plot(data_list, acc_test_0, label=\"Test MAE\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_1, label=\"Train MSE\")\n",
    "    plt.plot(data_list, acc_valid_1, label=\"Valid MSE\")\n",
    "    plt.plot(data_list, acc_test_1, label=\"Test MSE\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6)) \n",
    "    plt.title(\"Feature reducion with Multicollinearity - \"+ imputing_title+\" imputing method - \"+ model_title+\" model\")\n",
    "    plt.xticks(rotation=90)\n",
    "    # Adding legends  \n",
    "    plt.plot(data_list, acc_train_2, label=\"Train R2\")\n",
    "    plt.plot(data_list, acc_valid_2, label=\"Valid R2\")\n",
    "    plt.plot(data_list, acc_test_2, label=\"Test R2\")\n",
    "    # Adding a title\n",
    "    plt.legend()\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "    np.savetxt(model_title+'_acc_train_0.txt',acc_train_0)\n",
    "    np.savetxt(model_title+'_acc_train_1.txt',acc_train_1)\n",
    "    np.savetxt(model_title+'_acc_train_2.txt',acc_train_2)\n",
    "    np.savetxt(model_title+'_acc_valid_0.txt',acc_valid_0)\n",
    "    np.savetxt(model_title+'_acc_valid_1.txt',acc_valid_1)\n",
    "    np.savetxt(model_title+'_acc_valid_2.txt',acc_valid_2)\n",
    "    np.savetxt(model_title+'_acc_test_0.txt',acc_test_0)\n",
    "    np.savetxt(model_title+'_acc_test_1.txt',acc_test_1)\n",
    "    np.savetxt(model_title+'_acc_test_2.txt',acc_test_2)\n",
    "    '''\n",
    "    return  acc_train_0 ,acc_test_0,acc_valid_0,acc_train_1,acc_test_1,acc_valid_1,acc_train_2,acc_test_2,acc_valid_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "315d6255-aee5-40e7-854b-8f6254de9979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Linear Regression - KNN 0 ('train 2890.81 +-49.64 63707439.0 +-1938650.0 84.79 +-0.71 ', 'valid 2911.63 +-222.27 65453751.0 +-17555662.0 81.28 +-8.79 ', 'test 2622.44 +-43.23 38350510.0 +-829790.0 90.13 +-0.21 ')\n",
      "Linear Regression - KNN 1 ('train 2890.81 +-49.64 63707439.0 +-1938650.0 84.79 +-0.71 ', 'valid 2911.63 +-222.27 65453751.0 +-17555662.0 81.28 +-8.79 ', 'test 2622.44 +-43.23 38350510.0 +-829790.0 90.13 +-0.21 ')\n",
      "Linear Regression - KNN 2 ('train 2890.81 +-49.64 63707439.0 +-1938650.0 84.79 +-0.71 ', 'valid 2911.63 +-222.27 65453751.0 +-17555662.0 81.28 +-8.79 ', 'test 2622.44 +-43.23 38350510.0 +-829790.0 90.13 +-0.21 ')\n",
      "Linear Regression - KNN 3 ('train 2890.81 +-49.64 63707439.0 +-1938650.0 84.79 +-0.71 ', 'valid 2911.63 +-222.27 65453751.0 +-17555662.0 81.28 +-8.79 ', 'test 2622.44 +-43.23 38350510.0 +-829790.0 90.13 +-0.21 ')\n",
      "Linear Regression - KNN 4 ('train 2890.81 +-49.64 63707439.0 +-1938650.0 84.79 +-0.71 ', 'valid 2911.63 +-222.27 65453751.0 +-17555662.0 81.28 +-8.79 ', 'test 2622.44 +-43.23 38350510.0 +-829790.0 90.13 +-0.21 ')\n",
      "Linear Regression - KNN 5 ('train 2890.81 +-49.64 63707439.0 +-1938650.0 84.79 +-0.71 ', 'valid 2911.63 +-222.27 65453751.0 +-17555662.0 81.28 +-8.79 ', 'test 2622.44 +-43.23 38350510.0 +-829790.0 90.13 +-0.21 ')\n",
      "Linear Regression - KNN 6 ('train 2890.81 +-49.64 63707439.0 +-1938650.0 84.79 +-0.71 ', 'valid 2911.63 +-222.27 65453751.0 +-17555662.0 81.28 +-8.79 ', 'test 2622.44 +-43.23 38350510.0 +-829790.0 90.13 +-0.21 ')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, model_title \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m( models,models_name):\n\u001b[0;32m     17\u001b[0m        \u001b[38;5;28mprint\u001b[39m(model_title)\n\u001b[1;32m---> 18\u001b[0m        PCA_assessment(X_train_knn ,y_train_knn, X_test_knn , y_test_knn, model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m'\u001b[39m, model_title)\n\u001b[0;32m     19\u001b[0m        PCA_assessment(X_train_em , y_train_em,X_test_em  ,y_test_knn, model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEM\u001b[39m\u001b[38;5;124m'\u001b[39m, model_title)\n\u001b[0;32m     20\u001b[0m        PCA_assessment(X_train_ct,  X_test_ct , y_train_ct ,y_test_knn, model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCT\u001b[39m\u001b[38;5;124m'\u001b[39m, model_title)\n",
      "Cell \u001b[1;32mIn[26], line 31\u001b[0m, in \u001b[0;36mPCA_assessment\u001b[1;34m(X_train, y_train, X_test, y_test, model, imputing_title, model_title)\u001b[0m\n\u001b[0;32m     24\u001b[0m pca_X_test \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     25\u001b[0m eigenvalues_ \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mexplained_variance_\n\u001b[1;32m---> 31\u001b[0m b \u001b[38;5;241m=\u001b[39m apply_model(model, X_train,y_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), X_test, y_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), to_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_title , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, imputing_title ,i, b)\n\u001b[0;32m     33\u001b[0m acc_train_0\u001b[38;5;241m.\u001b[39mappend( b[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m, in \u001b[0;36mapply_model\u001b[1;34m(model, X_train, y_train, X_test, y_test, to_string)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_model\u001b[39m(model,X_train,y_train,X_test, y_test, to_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m ):\n\u001b[1;32m----> 3\u001b[0m     ma_t,ms_t,r2_t \u001b[38;5;241m=\u001b[39m train_clf(model,X_train,y_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),X_test, y_test,\u001b[38;5;28;01mFalse\u001b[39;00m, to_string )\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ma_t,ms_t,r2_t\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mtrain_clf\u001b[1;34m(clf, X_tr, y_tr, X_test, y_test, print_ind, to_string)\u001b[0m\n\u001b[0;32m     10\u001b[0m X_valid \u001b[38;5;241m=\u001b[39m X_tr[valid_index]\n\u001b[0;32m     11\u001b[0m y_valid \u001b[38;5;241m=\u001b[39m y_tr[valid_index]\n\u001b[1;32m---> 16\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m     18\u001b[0m res \u001b[38;5;241m=\u001b[39m clf_score(clf,X_train,y_train)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (print_ind): \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain: \u001b[39m\u001b[38;5;124m'\u001b[39m, res)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:665\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n\u001b[0;32m    664\u001b[0m \u001b[38;5;66;03m# Sample weight can be implemented via a simple rescaling.\u001b[39;00m\n\u001b[1;32m--> 665\u001b[0m X, y, sample_weight_sqrt \u001b[38;5;241m=\u001b[39m _rescale_data(X, y, sample_weight)\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive:\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:322\u001b[0m, in \u001b[0;36m_rescale_data\u001b[1;34m(X, y, sample_weight)\u001b[0m\n\u001b[0;32m    320\u001b[0m sample_weight_sqrt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(sample_weight)\n\u001b[0;32m    321\u001b[0m sw_matrix \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mdia_matrix((sample_weight_sqrt, \u001b[38;5;241m0\u001b[39m), shape\u001b[38;5;241m=\u001b[39m(n_samples, n_samples))\n\u001b[1;32m--> 322\u001b[0m X \u001b[38;5;241m=\u001b[39m safe_sparse_dot(sw_matrix, X)\n\u001b[0;32m    323\u001b[0m y \u001b[38;5;241m=\u001b[39m safe_sparse_dot(sw_matrix, y)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, sample_weight_sqrt\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    196\u001b[0m ):\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:624\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    623\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_dispatch(other)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:526\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_vector(other\u001b[38;5;241m.\u001b[39mravel())\u001b[38;5;241m.\u001b[39mreshape(M, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m N:\n\u001b[1;32m--> 526\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_multivector(other)\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:594\u001b[0m, in \u001b[0;36m_spbase._mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mul_multivector\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtocsr()\u001b[38;5;241m.\u001b[39m_mul_multivector(other)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:955\u001b[0m, in \u001b[0;36m_spbase.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtocsr\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert this array to Compressed Sparse Row format.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \n\u001b[0;32m    952\u001b[0m \u001b[38;5;124;03m    With copy=False, the data/indices may be shared between this array and\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;124;03m    the resultant csr_array.\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtocoo(copy\u001b[38;5;241m=\u001b[39mcopy)\u001b[38;5;241m.\u001b[39mtocsr(copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_dia.py:413\u001b[0m, in \u001b[0;36m_dia_base.tocoo\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    410\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[mask]\n\u001b[0;32m    411\u001b[0m \u001b[38;5;66;03m# Note: this cannot set has_canonical_format=True, because despite the\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[38;5;66;03m# lack of duplicates, we do not generate sorted indices.\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coo_container(\n\u001b[0;32m    414\u001b[0m     (data, (row, col)), shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    415\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_coo.py:204\u001b[0m, in \u001b[0;36m_coo_base.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_coo.py:290\u001b[0m, in \u001b[0;36m_coo_base._check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m to_native(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnnz \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow index exceeds matrix dimensions\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:41\u001b[0m, in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " models = [\n",
    "          LinearRegression(),\n",
    "          GradientBoostingRegressor(),\n",
    "          RandomForestRegressor(), \n",
    "          SVR(), \n",
    "          MLPRegressor( alpha=1e-5, max_iter=5000,hidden_layer_sizes=(32, 32), random_state=1),\n",
    "         ]\n",
    "models_name = [\n",
    "         'Linear Regression',\n",
    "          'Gradient Boosting Regressor',\n",
    "          'Random Forest Regressor', \n",
    "          'SVR', \n",
    "          'MLP Regressor'  \n",
    "]\n",
    "\n",
    "for model, model_title in zip( models,models_name):\n",
    "        print(model_title)\n",
    "        PCA_assessment(X_train_knn ,y_train_knn, X_test_knn , y_test_knn, model, 'KNN', model_title)\n",
    "        PCA_assessment(X_train_em , y_train_em,X_test_em  ,y_test_knn, model, 'EM', model_title)\n",
    "        PCA_assessment(X_train_ct,  X_test_ct , y_train_ct ,y_test_knn, model, 'CT', model_title)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c36982-1f68-4810-9985-1060936b1112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
